#!/usr/bin/env python3
"""
D√©monstration du scraping HTTP avec requests + BeautifulSoup
Montre comment le scraping fonctionne √©tape par √©tape
"""

import requests
from bs4 import BeautifulSoup
import json
from datetime import datetime


def demo_simple_http():
    """Exemple simple de requ√™te HTTP et parsing HTML."""

    print("="*80)
    print("üåê D√âMO: Scraping HTTP avec Requests + BeautifulSoup")
    print("="*80)
    print()

    # 1. Configuration
    print("üìã √âtape 1: Configuration")
    print("-" * 80)

    url = "https://www.pap.fr/annonce/vente-appartement-paris-75"
    headers = {
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
    }

    print(f"URL cible: {url}")
    print(f"User-Agent: {headers['User-Agent'][:50]}...")
    print()

    # 2. Requ√™te HTTP
    print("üì° √âtape 2: Envoi de la requ√™te HTTP GET")
    print("-" * 80)

    try:
        response = requests.get(url, headers=headers, timeout=10)
        print(f"‚úÖ Status Code: {response.status_code}")
        print(f"‚úÖ Content-Type: {response.headers.get('Content-Type', 'N/A')}")
        print(f"‚úÖ Taille de la r√©ponse: {len(response.content):,} bytes")
        print()

        # 3. Parsing HTML
        print("üîç √âtape 3: Parsing du HTML avec BeautifulSoup")
        print("-" * 80)

        soup = BeautifulSoup(response.content, 'lxml')
        print(f"‚úÖ Parser utilis√©: lxml")
        print(f"‚úÖ Title de la page: {soup.title.string if soup.title else 'N/A'}")
        print()

        # 4. Extraction des donn√©es (exemple g√©n√©rique)
        print("üìä √âtape 4: Extraction des donn√©es")
        print("-" * 80)

        # Chercher des √©l√©ments typiques d'une page immobili√®re
        # (les s√©lecteurs varient selon le site)

        # Exemple: chercher tous les liens
        links = soup.find_all('a', href=True, limit=5)
        print(f"Liens trouv√©s (5 premiers):")
        for i, link in enumerate(links, 1):
            href = link.get('href', '')
            text = link.get_text(strip=True)[:50]
            print(f"  {i}. {text} ‚Üí {href[:60]}")
        print()

        # Exemple: chercher des prix (pattern commun)
        prices = soup.find_all(text=lambda text: text and '‚Ç¨' in str(text))
        print(f"Prix potentiels trouv√©s: {len(prices[:5])}")
        for i, price in enumerate(prices[:3], 1):
            print(f"  {i}. {str(price).strip()[:50]}")
        print()

        # 5. Structure de donn√©es normalis√©e
        print("üì¶ √âtape 5: Structure de donn√©es normalis√©e")
        print("-" * 80)

        # Exemple de ce qu'on extrait vraiment
        example_listing = {
            "titre": "Appartement 3 pi√®ces - 75m¬≤ - Paris 15√®me",
            "date_publication": datetime.now().strftime('%Y-%m-%d'),
            "prix": 450000,
            "localisation": "Paris 15√®me",
            "lien": "https://www.pap.fr/annonce/exemple-123456",
            "site_source": "pap.fr",
            "photos": [
                "https://www.pap.fr/photos/exemple1.jpg",
                "https://www.pap.fr/photos/exemple2.jpg"
            ],
            "telephone": None,
            "surface": 75,
            "pieces": 3,
            "description": "Bel appartement..."
        }

        print("Exemple de donn√©es extraites:")
        print(json.dumps(example_listing, indent=2, ensure_ascii=False))
        print()

    except requests.RequestException as e:
        print(f"‚ùå Erreur HTTP: {e}")
        print()
        return None

    print("="*80)
    print("‚úÖ D√©mo termin√©e!")
    print("="*80)
    print()


def demo_with_selectors():
    """Exemple montrant les s√©lecteurs CSS."""

    print("="*80)
    print("üéØ D√âMO: S√©lecteurs CSS pour l'extraction")
    print("="*80)
    print()

    # HTML d'exemple (simul√©)
    example_html = """
    <html>
    <body>
        <div class="search-results">
            <article class="listing" data-id="12345">
                <h2 class="listing-title">Appartement 3 pi√®ces - Paris</h2>
                <span class="price">450 000 ‚Ç¨</span>
                <span class="location">Paris 15√®me</span>
                <div class="details">
                    <span class="surface">75 m¬≤</span>
                    <span class="rooms">3 pi√®ces</span>
                </div>
                <a href="/annonce/12345" class="listing-link">Voir l'annonce</a>
                <img src="photo1.jpg" alt="Photo appartement">
            </article>

            <article class="listing" data-id="67890">
                <h2 class="listing-title">Maison 5 pi√®ces - Lyon</h2>
                <span class="price">650 000 ‚Ç¨</span>
                <span class="location">Lyon 6√®me</span>
                <div class="details">
                    <span class="surface">120 m¬≤</span>
                    <span class="rooms">5 pi√®ces</span>
                </div>
                <a href="/annonce/67890" class="listing-link">Voir l'annonce</a>
                <img src="photo2.jpg" alt="Photo maison">
            </article>
        </div>
    </body>
    </html>
    """

    soup = BeautifulSoup(example_html, 'lxml')

    print("üìù HTML d'exemple charg√©")
    print()

    # D√©monstration des s√©lecteurs
    print("üîç S√©lecteurs CSS utilis√©s:")
    print("-" * 80)

    # 1. Trouver toutes les annonces
    listings = soup.find_all('article', class_='listing')
    print(f"1. soup.find_all('article', class_='listing')")
    print(f"   ‚Üí {len(listings)} annonces trouv√©es")
    print()

    # 2. Pour chaque annonce, extraire les donn√©es
    for i, listing in enumerate(listings, 1):
        print(f"Annonce #{i}:")

        # Titre
        title = listing.find('h2', class_='listing-title')
        print(f"  ‚Ä¢ Titre: {title.get_text(strip=True) if title else 'N/A'}")

        # Prix
        price = listing.find('span', class_='price')
        print(f"  ‚Ä¢ Prix: {price.get_text(strip=True) if price else 'N/A'}")

        # Localisation
        location = listing.find('span', class_='location')
        print(f"  ‚Ä¢ Localisation: {location.get_text(strip=True) if location else 'N/A'}")

        # Surface
        surface = listing.find('span', class_='surface')
        print(f"  ‚Ä¢ Surface: {surface.get_text(strip=True) if surface else 'N/A'}")

        # Lien
        link = listing.find('a', class_='listing-link')
        print(f"  ‚Ä¢ Lien: {link.get('href') if link else 'N/A'}")

        # Photo
        img = listing.find('img')
        print(f"  ‚Ä¢ Photo: {img.get('src') if img else 'N/A'}")

        print()


def demo_comparison():
    """Comparaison Requests vs Playwright."""

    print("="*80)
    print("‚öñÔ∏è  COMPARAISON: Requests vs Playwright")
    print("="*80)
    print()

    comparison = {
        "Requests + BeautifulSoup": {
            "Avantages": [
                "‚úÖ Rapide (pas de navigateur)",
                "‚úÖ L√©ger en m√©moire",
                "‚úÖ Simple √† utiliser",
                "‚úÖ Parfait pour HTML statique"
            ],
            "Inconv√©nients": [
                "‚ùå Pas de JavaScript",
                "‚ùå Pas de contenu dynamique",
                "‚ùå Pas de rendu CSS"
            ],
            "Utilis√© pour": [
                "pap.fr",
                "figaro-immo.fr"
            ]
        },
        "Playwright": {
            "Avantages": [
                "‚úÖ Ex√©cute JavaScript",
                "‚úÖ Contenu dynamique",
                "‚úÖ Scroll, clics, interactions",
                "‚úÖ Screenshots possibles"
            ],
            "Inconv√©nients": [
                "‚ùå Plus lent",
                "‚ùå Plus de m√©moire",
                "‚ùå Installation navigateur requise"
            ],
            "Utilis√© pour": [
                "leboncoin.fr",
                "facebook.com/marketplace"
            ]
        }
    }

    for method, details in comparison.items():
        print(f"üìå {method}")
        print("-" * 80)

        print("\nüü¢ Avantages:")
        for adv in details["Avantages"]:
            print(f"   {adv}")

        print("\nüî¥ Inconv√©nients:")
        for dis in details["Inconv√©nients"]:
            print(f"   {dis}")

        print(f"\nüéØ Utilis√© pour:")
        for site in details["Utilis√© pour"]:
            print(f"   ‚Ä¢ {site}")

        print("\n")


def main():
    """Point d'entr√©e de la d√©mo."""

    print("\n" + "üé¨ " * 20)
    print("D√âMONSTRATION: Comment fonctionne le scraping HTTP")
    print("üé¨ " * 20 + "\n")

    # Menu
    print("Choisissez une d√©mo:")
    print("  1. D√©mo simple HTTP (requ√™te r√©elle)")
    print("  2. D√©mo s√©lecteurs CSS (HTML d'exemple)")
    print("  3. Comparaison Requests vs Playwright")
    print("  4. Tout montrer")
    print()

    choice = input("Votre choix (1-4): ").strip()
    print()

    if choice == "1":
        demo_simple_http()
    elif choice == "2":
        demo_with_selectors()
    elif choice == "3":
        demo_comparison()
    elif choice == "4":
        demo_simple_http()
        demo_with_selectors()
        demo_comparison()
    else:
        print("‚ùå Choix invalide")

    print("\nüí° Pour scraper vraiment:")
    print("   python test_scrapers.py --ville Paris --site pap")
    print()


if __name__ == '__main__':
    main()
