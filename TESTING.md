# Guide de Test des Scrapers

## Installation des d√©pendances

```bash
pip install -r requirements.txt
playwright install
```

## Test rapide (sans base de donn√©es)

Le script [test_scrapers.py](test_scrapers.py) permet de tester les scrapers sans configurer Supabase.

### Tester un site sp√©cifique

```bash
# Test leboncoin
python test_scrapers.py --ville Paris --site leboncoin

# Test pap.fr
python test_scrapers.py --ville Lyon --site pap

# Test Facebook Marketplace
python test_scrapers.py --ville Marseille --site facebook

# Test Figaro Immo
python test_scrapers.py --ville Bordeaux --site figaro
```

### Tester tous les scrapers impl√©ment√©s

```bash
python test_scrapers.py --ville Paris --all
```

### Options disponibles

- `--ville` : Ville de recherche (requis)
- `--rayon` : Rayon de recherche en km (d√©faut: 10)
- `--max-pages` : Nombre max de pages √† scraper (d√©faut: 2)
- `--site` : Site sp√©cifique √† tester
- `--all` : Tester tous les scrapers

## Scrapers impl√©ment√©s

### ‚úÖ Leboncoin.fr (Playwright)
- **Status**: Impl√©ment√© et fonctionnel
- **Technologie**: Playwright (JavaScript dynamique)
- **Notes**: Site populaire, nombreuses annonces

### ‚úÖ Pap.fr (BeautifulSoup)
- **Status**: Impl√©ment√© et fonctionnel
- **Technologie**: Requests + BeautifulSoup
- **Notes**: Particuliers uniquement, HTML statique

### ‚úÖ Facebook Marketplace (Playwright)
- **Status**: Impl√©ment√© (√† tester)
- **Technologie**: Playwright
- **Notes**:
  - Peut √™tre bloqu√© par Facebook
  - N√©cessite des pr√©cautions (rate limiting)
  - Les s√©lecteurs peuvent changer fr√©quemment

### ‚úÖ Figaro Immobilier (BeautifulSoup)
- **Status**: Impl√©ment√© (template)
- **Technologie**: Requests + BeautifulSoup
- **Notes**: Annonces haut de gamme

### ‚ö†Ô∏è Autres sites (templates)
Les scrapers suivants sont des templates √† impl√©menter:
- `paruvendu.py`
- `logic_immo.py`
- `bienici.py`
- `seloger.py`

## Exemple de sortie

```
================================================================================
üß™ Test du scraper: leboncoin.fr
================================================================================

üîç Scraping leboncoin.fr pour Paris (rayon: 10km)
  üìÑ Page 1/2...
  üìÑ Page 2/2...
‚úÖ 40 annonces trouv√©es sur leboncoin.fr

üìä R√©sultats du scraping:
   - Total annonces: 40
   - Annonces valides: 38
   - Annonces de particuliers: 32

üìã Exemples d'annonces (max 3):

   1. Appartement 3 pi√®ces - 75m¬≤ - Paris 15√®me
      Prix: 450,000 ‚Ç¨
      Localisation: Paris 15√®me
      Lien: https://www.leboncoin.fr/annonce/...
      Valide: ‚úÖ

   ...
```

## Debugging

### Activer le mode verbose de Playwright

Modifier `scrapers/base.py` ou les scrapers individuels:

```python
browser = p.chromium.launch(
    headless=False,  # Voir le navigateur
    slow_mo=1000     # Ralentir les actions
)
```

### V√©rifier les s√©lecteurs CSS

Si un scraper ne trouve pas d'annonces, les s√©lecteurs CSS ont peut-√™tre chang√©:

1. Ouvrir le site dans un navigateur
2. Inspecter l'√©l√©ment (clic droit ‚Üí Inspecter)
3. Trouver le s√©lecteur CSS/XPath correct
4. Mettre √† jour le scraper

### Probl√®mes courants

**Timeout sur Playwright**
```bash
# Augmenter le timeout dans le scraper
page.goto(url, timeout=60000)  # 60 secondes
```

**Rate limiting / IP bloqu√©e**
```bash
# Augmenter le d√©lai entre requ√™tes dans .env
SCRAPING_DELAY=5
```

**S√©lecteurs invalides**
- Les sites changent r√©guli√®rement leur HTML
- V√©rifier et mettre √† jour les s√©lecteurs CSS

## Test avec la base de donn√©es

Une fois Supabase configur√©, tester le workflow complet:

```bash
# 1. Configurer .env
cp .env.example .env
# √âditer .env avec vos cl√©s Supabase

# 2. Lancer une prospection compl√®te
python main.py --user-id test-user --ville Paris --rayon 10

# 3. V√©rifier les r√©sultats dans Supabase
```

## Contribution

Pour ajouter un nouveau scraper:

1. Cr√©er `scrapers/nouveau_site.py`
2. H√©riter de `BaseScraper`
3. Impl√©menter la m√©thode `scrape()`
4. Ajouter au fichier `scrapers/__init__.py`
5. Ajouter au fichier `main.py`
6. Tester avec `test_scrapers.py`
