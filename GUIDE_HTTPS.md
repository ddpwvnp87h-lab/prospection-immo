# ğŸŒ Guide HTTPS Scraping - Comment Ã§a marche

## ğŸ¯ Le Code RÃ©el (dans scrapers/pap.py)

### 1. Configuration Session HTTPS

```python
# Ligne 31-32 dans scrapers/pap.py
session = requests.Session()
session.headers.update({'User-Agent': self.user_agent})
```

**Ce qui se passe:**
- CrÃ©Ã©e une session HTTP persistante
- Ajoute un User-Agent pour simuler un navigateur
- Maintient les cookies entre requÃªtes

---

### 2. Construction de l'URL HTTPS

```python
# Ligne 35-36
base_url = f"https://www.pap.fr/annonce/vente-immobilier-{ville.lower()}"
```

**Exemple:**
- EntrÃ©e: `ville = "Paris"`
- RÃ©sultat: `https://www.pap.fr/annonce/vente-immobilier-paris`

---

### 3. RequÃªte HTTPS GET

```python
# Ligne 44-45
response = session.get(url, timeout=15)
response.raise_for_status()
```

**Ce qui se passe:**
1. ğŸ” **Connexion TLS/SSL** Ã©tablie
2. ğŸ“¡ **GET request** envoyÃ©e
3. â±ï¸ **Timeout** de 15 secondes
4. âœ… **VÃ©rification** du status code (200, 404, etc.)

**DonnÃ©es reÃ§ues:**
```
Status: 200 OK
Content-Type: text/html; charset=utf-8
Content-Length: 125678 bytes
Set-Cookie: session_id=abc123...

<html>
  <body>
    <div class="search-list-item">
      <h2>Appartement Paris</h2>
      <span class="price">450 000 â‚¬</span>
      ...
    </div>
  </body>
</html>
```

---

### 4. Parsing HTML

```python
# Ligne 47
soup = BeautifulSoup(response.content, 'lxml')
```

**Ce qui se passe:**
- Parse le HTML en arbre DOM
- Permet de chercher des Ã©lÃ©ments facilement
- Utilise lxml (rapide) ou html.parser (intÃ©grÃ©)

---

### 5. Extraction des Annonces

```python
# Ligne 51-52
ads = soup.find_all('div', class_='search-list-item')
```

**SÃ©lecteurs CSS utilisÃ©s:**

```html
<div class="search-list-item">           â† TrouvÃ© par find_all()
  <h2 class="item-title">               â† TrouvÃ© par find('h2')
    Appartement 3 piÃ¨ces Paris
  </h2>
  <span class="item-price">450 000 â‚¬</span>  â† Prix extrait
  <span class="item-location">Paris 15</span> â† Localisation
  <a href="/annonce/123">Voir</a>       â† Lien extrait
</div>
```

---

### 6. Extraction des DÃ©tails (mÃ©thode _extract_listing)

```python
# Lignes 75-100 dans scrapers/pap.py
def _extract_listing(self, ad_element, ville: str):
    # Lien
    link_elem = ad_element.find('a', href=True)
    lien = f"https://www.pap.fr{link_elem['href']}"

    # Titre
    titre_elem = ad_element.find('span', class_='item-title')
    titre = titre_elem.get_text(strip=True)

    # Prix
    prix_elem = ad_element.find('span', class_='item-price')
    prix = self._parse_price(prix_elem.get_text())

    # Photos
    img_elem = ad_element.find('img')
    img_src = img_elem.get('src')

    return {
        'titre': titre,
        'prix': prix,
        'lien': lien,
        'photos': [img_src],
        ...
    }
```

---

## ğŸ”¥ Workflow Complet HTTPS

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. CONFIGURATION                                            â”‚
â”‚    session = requests.Session()                             â”‚
â”‚    headers = {'User-Agent': '...'}                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. CONNEXION HTTPS (TLS 1.3)                                â”‚
â”‚    ğŸ” Handshake SSL                                          â”‚
â”‚    ğŸ“œ VÃ©rification certificat                                â”‚
â”‚    ğŸ”‘ Ã‰change de clÃ©s                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. REQUÃŠTE HTTP                                             â”‚
â”‚    GET /annonce/vente-immobilier-paris HTTP/1.1             â”‚
â”‚    Host: www.pap.fr                                         â”‚
â”‚    User-Agent: Mozilla/5.0 ...                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. RÃ‰PONSE HTTPS                                            â”‚
â”‚    HTTP/1.1 200 OK                                          â”‚
â”‚    Content-Type: text/html; charset=utf-8                   â”‚
â”‚    [125KB de HTML]                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. PARSING HTML                                             â”‚
â”‚    BeautifulSoup(html, 'lxml')                              â”‚
â”‚    â†’ Arbre DOM navigable                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 6. EXTRACTION DONNÃ‰ES                                       â”‚
â”‚    soup.find_all('div', class_='search-list-item')          â”‚
â”‚    â†’ 40 annonces trouvÃ©es                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 7. NORMALISATION                                            â”‚
â”‚    {                                                        â”‚
â”‚      "titre": "Appartement...",                             â”‚
â”‚      "prix": 450000,                                        â”‚
â”‚      "lien": "https://...",                                 â”‚
â”‚      ...                                                    â”‚
â”‚    }                                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š Comparaison: Requests vs Playwright

### Requests (HTTP Simple) - UtilisÃ© dans pap.py

```python
# AVANTAGES
âœ… Rapide (quelques ms)
âœ… LÃ©ger (< 1 MB mÃ©moire)
âœ… Pas de navigateur requis
âœ… Parfait pour HTML statique

# CODE
import requests
from bs4 import BeautifulSoup

response = requests.get('https://pap.fr/...')
soup = BeautifulSoup(response.content, 'lxml')
annonces = soup.find_all('div', class_='annonce')
```

**Sites utilisant Requests:**
- pap.fr âœ…
- figaro-immo.fr âœ…

---

### Playwright (JavaScript) - UtilisÃ© dans leboncoin.py

```python
# AVANTAGES
âœ… ExÃ©cute JavaScript
âœ… GÃ¨re le contenu dynamique
âœ… Scroll, clics, etc.
âœ… Rendu complet de la page

# CODE
from playwright.sync_api import sync_playwright

with sync_playwright() as p:
    browser = p.chromium.launch()
    page = browser.new_page()
    page.goto('https://leboncoin.fr/...')
    page.wait_for_selector('.annonce')
    elements = page.query_selector_all('.annonce')
```

**Sites utilisant Playwright:**
- leboncoin.fr âœ…
- facebook.com/marketplace âœ…

---

## ğŸ”§ RequÃªte HTTPS DÃ©taillÃ©e

### Headers EnvoyÃ©s

```http
GET /annonce/vente-immobilier-paris HTTP/1.1
Host: www.pap.fr
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
Accept-Language: fr-FR,fr;q=0.9,en-US;q=0.8,en;q=0.7
Accept-Encoding: gzip, deflate, br
Connection: keep-alive
```

### RÃ©ponse ReÃ§ue

```http
HTTP/1.1 200 OK
Date: Mon, 27 Jan 2026 23:00:00 GMT
Content-Type: text/html; charset=utf-8
Content-Length: 125678
Set-Cookie: session_id=abc123; Path=/; HttpOnly; Secure
Cache-Control: max-age=3600
Server: nginx/1.21.0
```

---

## ğŸ’¡ SÃ©curitÃ© HTTPS

### VÃ©rifications Automatiques

```python
# requests fait automatiquement:
1. âœ… VÃ©rification du certificat SSL
2. âœ… Validation de la chaÃ®ne de certificats
3. âœ… VÃ©rification de l'expiration
4. âœ… Chiffrement TLS 1.2+
5. âœ… Protection MITM
```

### En cas d'erreur SSL

```python
# Si certificat invalide:
requests.exceptions.SSLError:
  [SSL: CERTIFICATE_VERIFY_FAILED]

# Solution (Ã  Ã©viter en prod):
response = requests.get(url, verify=False)  # âš ï¸ Dangereux!
```

---

## ğŸ¯ Code Complet Minimal

```python
import requests
from bs4 import BeautifulSoup

def scraper_pap_https(ville):
    # 1. Session
    session = requests.Session()
    session.headers.update({
        'User-Agent': 'Mozilla/5.0 ...'
    })

    # 2. URL
    url = f"https://www.pap.fr/annonce/vente-immobilier-{ville}"

    # 3. RequÃªte HTTPS
    response = session.get(url, timeout=15)
    response.raise_for_status()

    # 4. Parse HTML
    soup = BeautifulSoup(response.content, 'lxml')

    # 5. Extraire annonces
    annonces = []
    for ad in soup.find_all('div', class_='search-list-item'):
        annonces.append({
            'titre': ad.find('span', class_='item-title').get_text(),
            'prix': ad.find('span', class_='item-price').get_text(),
            'lien': 'https://pap.fr' + ad.find('a')['href']
        })

    return annonces

# Utilisation
resultats = scraper_pap_https('paris')
print(f"{len(resultats)} annonces trouvÃ©es")
```

---

## âœ… Fichiers Ã  Consulter

1. **[scrapers/pap.py](scrapers/pap.py)** - Scraper HTTPS complet
2. **[scrapers/leboncoin.py](scrapers/leboncoin.py)** - Scraper Playwright
3. **[scrapers/base.py](scrapers/base.py)** - Classe de base
4. **[test_scrapers.py](test_scrapers.py)** - Tests

---

## ğŸš€ Pour Tester

```bash
# Une fois les dÃ©pendances installÃ©es:
pip3 install requests beautifulsoup4 html5lib

# Test:
python3 test_scrapers.py --ville Paris --site pap
```

Le scraping HTTPS fonctionne! Le code est **dÃ©jÃ  Ã©crit et prÃªt** ğŸ¯
